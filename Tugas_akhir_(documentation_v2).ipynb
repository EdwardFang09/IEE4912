{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwardFang09/IEE4912/blob/main/Tugas_akhir_(documentation_v2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msdN5ggYEIUF"
      },
      "source": [
        "<h1> CIT Education Assistant\n",
        "\n",
        "_________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lks2elQ5EIUG"
      },
      "source": [
        "Featuers:\n",
        "- Google search image\n",
        "- Mentimeter\n",
        "- Kahoot\n",
        "- Start class and end class (sqlite (theoretical))\n",
        "- Web Based CRUD (not done)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfdeKCbNEIUH"
      },
      "source": [
        "Faster whisper\n",
        "https://github.com/SYSTRAN/faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndygxt5CEIUH",
        "outputId": "13b5f376-30f9-4829-8f90-255851af2129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0+cu126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svw4SE6qHISX"
      },
      "source": [
        "Without trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGWr2759EIUI",
        "outputId": "fd9e3a16-9fd1-49e1-aa85-53c06f70f902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.36s]  Okay, so I'll open Google.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.00s]  Hey Sora Open Google\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 27.555555555555557\n",
            "Standard Deviation: 12.893677271447697\n",
            "Confidence Threshold: 40.44923282700326\n",
            "Matched command: google\n",
            "Command:  google\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.20s]  Sora, buka Google.\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 23.333333333333332\n",
            "Standard Deviation: 14.514360704718161\n",
            "Confidence Threshold: 37.84769403805149\n",
            "Matched command: google\n",
            "Command:  google\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.04s]  Surah, buka mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 1.88s]  Surah Buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 0.80s]  SORAH\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 19.88888888888889\n",
            "Standard Deviation: 13.584668191624822\n",
            "Confidence Threshold: 33.473557080513714\n",
            "Matched command: open kahoot\n",
            "Command:  open kahoot\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.00s]  Buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.60s]  Surah, buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 3.76s]  Sora Open Mentimeter\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 31.333333333333332\n",
            "Standard Deviation: 20.98147330914162\n",
            "Confidence Threshold: 52.31480664247495\n",
            "Matched command: open mentimeter\n",
            "Command:  open mentimeter\n",
            "Listening for commands...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 178\u001b[0m\n\u001b[0;32m    175\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m# Close database connection when exiting\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[7], line 171\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m should_run:\n\u001b[1;32m--> 171\u001b[0m         command \u001b[38;5;241m=\u001b[39m \u001b[43mlisten_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Directly listen for command\u001b[39;00m\n\u001b[0;32m    172\u001b[0m         perform_command(command)\n\u001b[0;32m    173\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mlisten_for_command\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening for commands...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 52\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import whisper\n",
        "import warnings\n",
        "import time\n",
        "import webbrowser\n",
        "import pyttsx3\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "import sqlite3\n",
        "import datetime\n",
        "from thefuzz import fuzz  # Import thefuzz\n",
        "import numpy as np\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize speech recognition, TTS engine, and Whisper model\n",
        "recognizer = sr.Recognizer()\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "model_size = \"turbo\"  # or smaller, depending on your resources\n",
        "base_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float32\") # or cpu\n",
        "\n",
        "assistant_name = \"sora mk.0\"\n",
        "should_run = True\n",
        "source = sr.Microphone()\n",
        "\n",
        "# Database setup (SQLite)\n",
        "DATABASE_FILE = \"class_data.db\"  # Name of your database file\n",
        "conn = sqlite3.connect(DATABASE_FILE)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if it doesn't exist\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS classes (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        start_time TEXT,\n",
        "        end_time TEXT\n",
        "    )\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "def respond(text):\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def listen_for_command():\n",
        "    with source as s:\n",
        "        print(\"Listening for commands...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        with open(\"command.wav\", \"wb\") as f:\n",
        "            f.write(audio.get_wav_data())\n",
        "\n",
        "        command, info = base_model.transcribe(r\"command.wav\", language='en')\n",
        "        print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "\n",
        "        if command:\n",
        "            full_command_text = \"\"\n",
        "            for segment in command:\n",
        "                print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "                full_command_text += segment.text + \" \"\n",
        "            full_command_text = full_command_text.strip().lower()\n",
        "\n",
        "            # Check for \"sora\" first\n",
        "            if \"sora\" in full_command_text:\n",
        "                print(\"Sora detected. Proceeding with command recognition.\")\n",
        "                # Proceed to command matching\n",
        "            else:\n",
        "                print(\"No 'sora' detected. Waiting for trigger word.\")\n",
        "                return None  # Wait for the trigger word\n",
        "\n",
        "            # Fuzzy matching logic (now only runs IF \"sora\" is present)\n",
        "            best_match = None\n",
        "            best_score = 0\n",
        "\n",
        "            commands = {\n",
        "                \"find\": \"find\",\n",
        "                \"open mentimeter\": \"open mentimeter\",\n",
        "                \"open kahoot\": \"open kahoot\",\n",
        "                \"start class\": \"start class\",\n",
        "                \"end class\": \"end class\",\n",
        "                \"exit\": \"exit\",\n",
        "                \"google\": \"google\",\n",
        "                \"chrome\":  \"chrome\",\n",
        "                \"browser\": \"browser\"\n",
        "\n",
        "            }\n",
        "\n",
        "            scores = []\n",
        "            for cmd, target in commands.items():\n",
        "                score = fuzz.ratio(full_command_text, target)\n",
        "                scores.append(score)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_match = cmd\n",
        "\n",
        "            # One Sigma Calculation and Threshold\n",
        "            scores_array = np.array(scores)\n",
        "            average_score = np.mean(scores_array)\n",
        "            standard_deviation = np.std(scores_array)\n",
        "\n",
        "            confidence_threshold = average_score + standard_deviation\n",
        "\n",
        "            print(f\"Average Score: {average_score}\")\n",
        "            print(f\"Standard Deviation: {standard_deviation}\")\n",
        "            print(f\"Confidence Threshold: {confidence_threshold}\")\n",
        "\n",
        "\n",
        "            if best_score >= confidence_threshold:\n",
        "                print(\"Matched command:\", best_match)\n",
        "                return best_match\n",
        "            else:\n",
        "                print(\"Command not recognized with sufficient confidence.\")\n",
        "                return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio. Please try again.\")\n",
        "        return None\n",
        "    except sr.RequestError:\n",
        "        print(\"Unable to access the speech recognition API.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def perform_command(command):\n",
        "    global should_run\n",
        "    if command:\n",
        "        print(\"Command: \", command)\n",
        "        if \"find\" in command:\n",
        "            query = command.replace(\"find\", \"\").strip()\n",
        "            respond(f\"Finding images of {query}\")\n",
        "            try:\n",
        "                search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "                webbrowser.open(search_url)\n",
        "            except Exception as e:\n",
        "                respond(f\"Sorry, I encountered an error during image search: {e}\")\n",
        "        elif \"open mentimeter\" in command:\n",
        "            respond(\"Opening Mentimeter.\")\n",
        "            webbrowser.open(\"https://www.mentimeter.com/\")\n",
        "        elif \"open kahoot\" in command:\n",
        "            respond(\"Opening Kahoot.\")\n",
        "            webbrowser.open(\"https://kahoot.com/\")\n",
        "        elif \"start class\" in command:\n",
        "            start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"INSERT INTO classes (start_time) VALUES (?)\", (start_time,))  # Only start time\n",
        "            conn.commit()\n",
        "            respond(\"Class started.\")\n",
        "        elif \"end class\" in command:\n",
        "            end_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"UPDATE classes SET end_time =? WHERE end_time IS NULL ORDER BY id DESC LIMIT 1\", (end_time,)) # Update the latest started class\n",
        "            conn.commit()\n",
        "            respond(\"Class ended.\")\n",
        "        elif \"google\" in command or \"chrome\" in command or \"browser\" in command:\n",
        "            respond(\"Opening Google.\")\n",
        "            webbrowser.open(\"www.google.com\")  # Or \"https://www.google.com\"\n",
        "        elif \"exit\" in command:\n",
        "            should_run = False\n",
        "        else:\n",
        "            respond(\"I don't understand that command.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    while should_run:\n",
        "        command = listen_for_command()  # Directly listen for command\n",
        "        perform_command(command)\n",
        "        time.sleep(1)\n",
        "    respond(\"Goodbye.\")\n",
        "    conn.close() # Close database connection when exiting\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v_L3NEjHNkB"
      },
      "source": [
        "Trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk4neCiwM8Qx",
        "outputId": "01c97cb5-7f40-4ff3-b5fa-4027c347d3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0+cu126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening for commands...\n",
            "Transcription: sora start class\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 27.555555555555557\n",
            "Standard Deviation: 23.065660436198755\n",
            "Confidence Threshold: 50.62121599175431\n",
            "Matched command: start class\n",
            "Command:  start class\n",
            "Listening for commands...\n",
            "Transcription: sora end class\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 33.55555555555556\n",
            "Standard Deviation: 21.592751412922045\n",
            "Confidence Threshold: 55.1483069684776\n",
            "Matched command: end class\n",
            "Command:  end class\n",
            "Listening for commands...\n",
            "Transcription: sora end class\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 33.55555555555556\n",
            "Standard Deviation: 21.592751412922045\n",
            "Confidence Threshold: 55.1483069684776\n",
            "Matched command: end class\n",
            "Command:  end class\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: you\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: oh\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: done\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: you\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Transcription: s\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 194\u001b[0m\n\u001b[0;32m    191\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m# Close database connection when exiting\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[3], line 187\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m should_run:\n\u001b[1;32m--> 187\u001b[0m         command \u001b[38;5;241m=\u001b[39m \u001b[43mlisten_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Directly listen for command\u001b[39;00m\n\u001b[0;32m    188\u001b[0m         perform_command(command)\n\u001b[0;32m    189\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[3], line 69\u001b[0m, in \u001b[0;36mlisten_for_command\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening for commands...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 69\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:492\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m>\u001b[39m timeout:\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlistening timed out while waiting for phrase to start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    494\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# prompt: same like the code above, but i want to use EdwardFang09/whisper-base-TA-2025 from huggingface. reprint the code above with different model i mentioned\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "import whisper\n",
        "import warnings\n",
        "import time\n",
        "import webbrowser\n",
        "import pyttsx3\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "import sqlite3\n",
        "import datetime\n",
        "from thefuzz import fuzz  # Import thefuzz\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "\n",
        "# <h1> Sora assistant\n",
        "# Featuers:\n",
        "# - Google search image\n",
        "# - Mentimeter\n",
        "# - Kahoot\n",
        "# - Start class and end class (sqlite (theoretical))\n",
        "# - Web Based CRUD (not done)\n",
        "# Faster whisper\n",
        "# https://github.com/SYSTRAN/faster-whisper\n",
        "print(torch.__version__)\n",
        "torch.cuda.is_available()\n",
        "# Without trained model\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize speech recognition, TTS engine, and Whisper model\n",
        "recognizer = sr.Recognizer()\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# Load the model from Hugging Face\n",
        "pipe = pipeline(model=\"EdwardFang09/whisper-base-TA-2025_v2\")\n",
        "\n",
        "\n",
        "assistant_name = \"sora mk.0\"\n",
        "should_run = True\n",
        "source = sr.Microphone()\n",
        "\n",
        "# Database setup (SQLite)\n",
        "DATABASE_FILE = \"class_data.db\"  # Name of your database file\n",
        "conn = sqlite3.connect(DATABASE_FILE)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if it doesn't exist\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS classes (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        start_time TEXT,\n",
        "        end_time TEXT\n",
        "    )\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "def respond(text):\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def listen_for_command():\n",
        "    with source as s:\n",
        "        print(\"Listening for commands...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        with open(\"command.wav\", \"wb\") as f:\n",
        "            f.write(audio.get_wav_data())\n",
        "\n",
        "        # Use the Hugging Face pipeline for transcription\n",
        "        transcription = pipe(\"command.wav\")\n",
        "        full_command_text = transcription[\"text\"].strip().lower()\n",
        "        print(f\"Transcription: {full_command_text}\")\n",
        "\n",
        "        # Check for \"sora\" first\n",
        "        if \"sora\" in full_command_text:\n",
        "            print(\"Sora detected. Proceeding with command recognition.\")\n",
        "            # Proceed to command matching\n",
        "        else:\n",
        "            print(\"No 'sora' detected. Waiting for trigger word.\")\n",
        "            return None  # Wait for the trigger word\n",
        "\n",
        "        # Fuzzy matching logic (now only runs IF \"sora\" is present)\n",
        "        best_match = None\n",
        "        best_score = 0\n",
        "\n",
        "        commands = {\n",
        "            \"find\": \"find\",\n",
        "            \"open mentimeter\": \"open mentimeter\",\n",
        "            \"open kahoot\": \"open kahoot\",\n",
        "            \"start class\": \"start class\",\n",
        "            \"end class\": \"end class\",\n",
        "            \"exit\": \"exit\",\n",
        "            \"google\": \"google\",\n",
        "            \"chrome\": \"chrome\",\n",
        "            \"browser\": \"browser\"\n",
        "        }\n",
        "\n",
        "        scores = []\n",
        "        for cmd, target in commands.items():\n",
        "            score = fuzz.ratio(full_command_text, target)\n",
        "            scores.append(score)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = cmd\n",
        "\n",
        "        # One Sigma Calculation and Threshold\n",
        "        scores_array = np.array(scores)\n",
        "        average_score = np.mean(scores_array)\n",
        "        standard_deviation = np.std(scores_array)\n",
        "\n",
        "        confidence_threshold = average_score + standard_deviation\n",
        "\n",
        "        print(f\"Average Score: {average_score}\")\n",
        "        print(f\"Standard Deviation: {standard_deviation}\")\n",
        "        print(f\"Confidence Threshold: {confidence_threshold}\")\n",
        "\n",
        "        if best_score >= confidence_threshold:\n",
        "            print(\"Matched command:\", best_match)\n",
        "            return best_match\n",
        "        else:\n",
        "            print(\"Command not recognized with sufficient confidence.\")\n",
        "            return None\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio. Please try again.\")\n",
        "        return None\n",
        "    except sr.RequestError:\n",
        "        print(\"Unable to access the speech recognition API.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def perform_command(command):\n",
        "    global should_run\n",
        "    if command:\n",
        "        print(\"Command: \", command)\n",
        "        if \"find\" in command:\n",
        "            query = command.replace(\"find\", \"\").strip()\n",
        "            respond(f\"Finding images of {query}\")\n",
        "            try:\n",
        "                search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "                webbrowser.open(search_url)\n",
        "            except Exception as e:\n",
        "                respond(f\"Sorry, I encountered an error during image search: {e}\")\n",
        "        elif \"mentimeter\" in command:\n",
        "            respond(\"Opening Mentimeter.\")\n",
        "            webbrowser.open(\"https://www.mentimeter.com/\")\n",
        "        elif \"kahoot\" in command:\n",
        "            respond(\"Opening Kahoot.\")\n",
        "            webbrowser.open(\"https://kahoot.com/\")\n",
        "        elif \"start class\" in command:\n",
        "            start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"INSERT INTO classes (start_time) VALUES (?)\", (start_time,))  # Only start time\n",
        "            conn.commit()\n",
        "            respond(\"Class started.\")\n",
        "        elif \"end class\" in command:\n",
        "            end_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Get the ID of the latest class with NULL end_time\n",
        "            cursor.execute(\"SELECT id FROM classes WHERE end_time IS NULL ORDER BY id DESC LIMIT 1\")\n",
        "            result = cursor.fetchone()\n",
        "\n",
        "            if result:\n",
        "                class_id = result[0]\n",
        "                cursor.execute(\"UPDATE classes SET end_time = ? WHERE id = ?\", (end_time, class_id))\n",
        "                conn.commit()\n",
        "                respond(\"Class ended.\")\n",
        "            else:\n",
        "                respond(\"No active class to end.\") # Handle case where there is no active class\n",
        "        elif \"google\" in command or \"chrome\" in command or \"browser\" in command:\n",
        "            respond(\"Opening Google.\")\n",
        "            webbrowser.open(\"www.google.com\")  # Or \"https://www.google.com\"\n",
        "        elif \"exit\" in command:\n",
        "            should_run = False\n",
        "        else:\n",
        "            respond(\"I don't understand that command.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    while should_run:\n",
        "        command = listen_for_command()  # Directly listen for command\n",
        "        perform_command(command)\n",
        "        time.sleep(1)\n",
        "    respond(\"Goodbye.\")\n",
        "    conn.close() # Close database connection when exiting\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: same like the code above, but i want to use EdwardFang09/whisper-base-TA-2025 from huggingface. reprint the code above with different model i mentioned\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "import whisper\n",
        "import warnings\n",
        "import time\n",
        "import webbrowser\n",
        "import pyttsx3\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "import sqlite3\n",
        "import datetime\n",
        "from thefuzz import fuzz  # Import thefuzz\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "\n",
        "# <h1> Sora assistant\n",
        "# Featuers:\n",
        "# - Google search image\n",
        "# - Mentimeter\n",
        "# - Kahoot\n",
        "# - Start class and end class (sqlite (theoretical))\n",
        "# - Web Based CRUD (not done)\n",
        "# Faster whisper\n",
        "# https://github.com/SYSTRAN/faster-whisper\n",
        "print(torch.__version__)\n",
        "torch.cuda.is_available()\n",
        "# Without trained model\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize speech recognition, TTS engine, and Whisper model\n",
        "recognizer = sr.Recognizer()\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# Load the model from Hugging Face\n",
        "pipe = pipeline(model=\"EdwardFang09/whisper-base-TA-2025_v2\")\n",
        "\n",
        "\n",
        "assistant_name = \"sora mk.0\"\n",
        "should_run = True\n",
        "source = sr.Microphone()\n",
        "\n",
        "# Database setup (SQLite)\n",
        "DATABASE_FILE = \"class_data.db\"  # Name of your database file\n",
        "conn = sqlite3.connect(DATABASE_FILE)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if it doesn't exist\n",
        "# Create tables if they don't exist\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS user (\n",
        "        user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        username TEXT,\n",
        "        password TEXT\n",
        "    )\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS log (\n",
        "        task_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        user_id INTEGER,\n",
        "        task_name TEXT,\n",
        "        created_at DATETIME,\n",
        "        FOREIGN KEY (user_id) REFERENCES user(user_id)\n",
        "    )\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS classes (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        start_time DATETIME,\n",
        "        end_time DATETIME\n",
        "    )\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "def respond(text):\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def listen_for_command():\n",
        "    with source as s:\n",
        "        print(\"Listening for commands...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        with open(\"command.wav\", \"wb\") as f:\n",
        "            f.write(audio.get_wav_data())\n",
        "\n",
        "        # Use the Hugging Face pipeline for transcription\n",
        "        transcription = pipe(\"command.wav\")\n",
        "        full_command_text = transcription[\"text\"].strip().lower()\n",
        "        print(f\"Transcription: {full_command_text}\")\n",
        "\n",
        "        # Check for \"sora\" first\n",
        "        if \"sora\" in full_command_text:\n",
        "            print(\"Sora detected. Proceeding with command recognition.\")\n",
        "            # Proceed to command matching\n",
        "        else:\n",
        "            print(\"No 'sora' detected. Waiting for trigger word.\")\n",
        "            return None  # Wait for the trigger word\n",
        "\n",
        "        # Fuzzy matching logic (now only runs IF \"sora\" is present)\n",
        "        best_match = None\n",
        "        best_score = 0\n",
        "\n",
        "        commands = {\n",
        "            \"find\": \"find\",\n",
        "            \"open mentimeter\": \"open mentimeter\",\n",
        "            \"open kahoot\": \"open kahoot\",\n",
        "            \"start class\": \"start class\",\n",
        "            \"end class\": \"end class\",\n",
        "            \"exit\": \"exit\",\n",
        "            \"google\": \"google\",\n",
        "            \"chrome\": \"chrome\",\n",
        "            \"browser\": \"browser\"\n",
        "        }\n",
        "\n",
        "        scores = []\n",
        "        for cmd, target in commands.items():\n",
        "            score = fuzz.ratio(full_command_text, target)\n",
        "            scores.append(score)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = cmd\n",
        "\n",
        "        # One Sigma Calculation and Threshold\n",
        "        scores_array = np.array(scores)\n",
        "        average_score = np.mean(scores_array)\n",
        "        standard_deviation = np.std(scores_array)\n",
        "\n",
        "        confidence_threshold = average_score + standard_deviation\n",
        "\n",
        "        print(f\"Average Score: {average_score}\")\n",
        "        print(f\"Standard Deviation: {standard_deviation}\")\n",
        "        print(f\"Confidence Threshold: {confidence_threshold}\")\n",
        "\n",
        "        if best_score >= confidence_threshold:\n",
        "            print(\"Matched command:\", best_match)\n",
        "            return best_match\n",
        "        else:\n",
        "            print(\"Command not recognized with sufficient confidence.\")\n",
        "            return None\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio. Please try again.\")\n",
        "        return None\n",
        "    except sr.RequestError:\n",
        "        print(\"Unable to access the speech recognition API.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def perform_command(command):\n",
        "    global should_run\n",
        "    if command:\n",
        "        print(\"Command: \", command)\n",
        "        if \"find\" in command:\n",
        "            query = command.replace(\"find\", \"\").strip()\n",
        "            respond(f\"Finding images of {query}\")\n",
        "            try:\n",
        "                search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "                webbrowser.open(search_url)\n",
        "            except Exception as e:\n",
        "                respond(f\"Sorry, I encountered an error during image search: {e}\")\n",
        "        elif \"mentimeter\" in command:\n",
        "            respond(\"Opening Mentimeter.\")\n",
        "            webbrowser.open(\"https://www.mentimeter.com/\")\n",
        "        elif \"kahoot\" in command:\n",
        "            respond(\"Opening Kahoot.\")\n",
        "            webbrowser.open(\"https://kahoot.com/\")\n",
        "        elif \"start class\" in command:\n",
        "            start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"INSERT INTO classes (start_time) VALUES (?)\", (start_time,))  # Only start time\n",
        "            conn.commit()\n",
        "            respond(\"Class started.\")\n",
        "        elif \"end class\" in command:\n",
        "            end_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Get the ID of the latest class with NULL end_time\n",
        "            cursor.execute(\"SELECT id FROM classes WHERE end_time IS NULL ORDER BY id DESC LIMIT 1\")\n",
        "            result = cursor.fetchone()\n",
        "\n",
        "            if result:\n",
        "                class_id = result[0]\n",
        "                cursor.execute(\"UPDATE classes SET end_time = ? WHERE id = ?\", (end_time, class_id))\n",
        "                conn.commit()\n",
        "                respond(\"Class ended.\")\n",
        "            else:\n",
        "                respond(\"No active class to end.\") # Handle case where there is no active class\n",
        "        elif \"google\" in command or \"chrome\" in command or \"browser\" in command:\n",
        "            respond(\"Opening Google.\")\n",
        "            webbrowser.open(\"www.google.com\")  # Or \"https://www.google.com\"\n",
        "        elif \"exit\" in command:\n",
        "            should_run = False\n",
        "        else:\n",
        "            respond(\"I don't understand that command.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    while should_run:\n",
        "        command = listen_for_command()  # Directly listen for command\n",
        "        perform_command(command)\n",
        "        time.sleep(1)\n",
        "    respond(\"Goodbye.\")\n",
        "    conn.close() # Close database connection when exiting\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "BwsCFO33Qx45"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}