{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwardFang09/IEE4912/blob/main/Tugas_akhir_(documentation_v2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msdN5ggYEIUF"
      },
      "source": [
        "<h1> Sora assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lks2elQ5EIUG"
      },
      "source": [
        "Features:\n",
        "- Google search image\n",
        "- Mentimeter\n",
        "- Kahoot\n",
        "- Start class and end class\n",
        "- Web Based CRUD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfdeKCbNEIUH"
      },
      "source": [
        "Faster whisper\n",
        "https://github.com/SYSTRAN/faster-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndygxt5CEIUH",
        "outputId": "13b5f376-30f9-4829-8f90-255851af2129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0+cu126\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svw4SE6qHISX"
      },
      "source": [
        "Without trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGWr2759EIUI",
        "outputId": "fd9e3a16-9fd1-49e1-aa85-53c06f70f902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.36s]  Okay, so I'll open Google.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.00s]  Hey Sora Open Google\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 27.555555555555557\n",
            "Standard Deviation: 12.893677271447697\n",
            "Confidence Threshold: 40.44923282700326\n",
            "Matched command: google\n",
            "Command:  google\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.20s]  Sora, buka Google.\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 23.333333333333332\n",
            "Standard Deviation: 14.514360704718161\n",
            "Confidence Threshold: 37.84769403805149\n",
            "Matched command: google\n",
            "Command:  google\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.04s]  Surah, buka mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 1.88s]  Surah Buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 0.80s]  SORAH\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 19.88888888888889\n",
            "Standard Deviation: 13.584668191624822\n",
            "Confidence Threshold: 33.473557080513714\n",
            "Matched command: open kahoot\n",
            "Command:  open kahoot\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.00s]  Buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 2.60s]  Surah, buka Mentimeter.\n",
            "No 'sora' detected. Waiting for trigger word.\n",
            "Listening for commands...\n",
            "Detected language 'en' with probability 1.000000\n",
            "[0.00s -> 3.76s]  Sora Open Mentimeter\n",
            "Sora detected. Proceeding with command recognition.\n",
            "Average Score: 31.333333333333332\n",
            "Standard Deviation: 20.98147330914162\n",
            "Confidence Threshold: 52.31480664247495\n",
            "Matched command: open mentimeter\n",
            "Command:  open mentimeter\n",
            "Listening for commands...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 178\u001b[0m\n\u001b[0;32m    175\u001b[0m     conn\u001b[38;5;241m.\u001b[39mclose() \u001b[38;5;66;03m# Close database connection when exiting\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[7], line 171\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m should_run:\n\u001b[1;32m--> 171\u001b[0m         command \u001b[38;5;241m=\u001b[39m \u001b[43mlisten_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Directly listen for command\u001b[39;00m\n\u001b[0;32m    172\u001b[0m         perform_command(command)\n\u001b[0;32m    173\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 52\u001b[0m, in \u001b[0;36mlisten_for_command\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening for commands...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[1;32m---> 52\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import whisper\n",
        "import warnings\n",
        "import time\n",
        "import webbrowser\n",
        "import pyttsx3\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "import sqlite3\n",
        "import datetime\n",
        "from thefuzz import fuzz  # Import thefuzz\n",
        "import numpy as np\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Initialize speech recognition, TTS engine, and Whisper model\n",
        "recognizer = sr.Recognizer()\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "model_size = \"turbo\"  # or smaller, depending on your resources\n",
        "base_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\") # or cpu\n",
        "\n",
        "assistant_name = \"sora mk.0\"\n",
        "should_run = True\n",
        "source = sr.Microphone()\n",
        "\n",
        "# Database setup (SQLite)\n",
        "DATABASE_FILE = \"class_data.db\"  # Name of your database file\n",
        "conn = sqlite3.connect(DATABASE_FILE)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create table if it doesn't exist\n",
        "cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS classes (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        start_time TEXT,\n",
        "        end_time TEXT\n",
        "    )\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "\n",
        "def respond(text):\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "def listen_for_command():\n",
        "    with source as s:\n",
        "        print(\"Listening for commands...\")\n",
        "        recognizer.adjust_for_ambient_noise(source)\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "    try:\n",
        "        with open(\"command.wav\", \"wb\") as f:\n",
        "            f.write(audio.get_wav_data())\n",
        "\n",
        "        command, info = base_model.transcribe(r\"command.wav\", language='en')\n",
        "        print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
        "\n",
        "        if command:\n",
        "            full_command_text = \"\"\n",
        "            for segment in command:\n",
        "                print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
        "                full_command_text += segment.text + \" \"\n",
        "            full_command_text = full_command_text.strip().lower()\n",
        "\n",
        "            # Check for \"sora\" first\n",
        "            if \"sora\" in full_command_text:\n",
        "                print(\"Sora detected. Proceeding with command recognition.\")\n",
        "                # Proceed to command matching\n",
        "            else:\n",
        "                print(\"No 'sora' detected. Waiting for trigger word.\")\n",
        "                return None  # Wait for the trigger word\n",
        "\n",
        "            # Fuzzy matching logic (now only runs IF \"sora\" is present)\n",
        "            best_match = None\n",
        "            best_score = 0\n",
        "\n",
        "            commands = {\n",
        "                \"find\": \"find\",\n",
        "                \"open mentimeter\": \"open mentimeter\",\n",
        "                \"open kahoot\": \"open kahoot\",\n",
        "                \"start class\": \"start class\",\n",
        "                \"end class\": \"end class\",\n",
        "                \"exit\": \"exit\",\n",
        "                \"google\": \"google\",\n",
        "                \"chrome\":  \"chrome\",\n",
        "                \"browser\": \"browser\"\n",
        "\n",
        "            }\n",
        "\n",
        "            scores = []\n",
        "            for cmd, target in commands.items():\n",
        "                score = fuzz.ratio(full_command_text, target)\n",
        "                scores.append(score)\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_match = cmd\n",
        "\n",
        "            # One Sigma Calculation and Threshold\n",
        "            scores_array = np.array(scores)\n",
        "            average_score = np.mean(scores_array)\n",
        "            standard_deviation = np.std(scores_array)\n",
        "\n",
        "            confidence_threshold = average_score + standard_deviation\n",
        "\n",
        "            print(f\"Average Score: {average_score}\")\n",
        "            print(f\"Standard Deviation: {standard_deviation}\")\n",
        "            print(f\"Confidence Threshold: {confidence_threshold}\")\n",
        "\n",
        "\n",
        "            if best_score >= confidence_threshold:\n",
        "                print(\"Matched command:\", best_match)\n",
        "                return best_match\n",
        "            else:\n",
        "                print(\"Command not recognized with sufficient confidence.\")\n",
        "                return None\n",
        "\n",
        "        return None\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio. Please try again.\")\n",
        "        return None\n",
        "    except sr.RequestError:\n",
        "        print(\"Unable to access the speech recognition API.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "def perform_command(command):\n",
        "    global should_run\n",
        "    if command:\n",
        "        print(\"Command: \", command)\n",
        "        if \"find\" in command:\n",
        "            query = command.replace(\"find\", \"\").strip()\n",
        "            respond(f\"Finding images of {query}\")\n",
        "            try:\n",
        "                search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "                webbrowser.open(search_url)\n",
        "            except Exception as e:\n",
        "                respond(f\"Sorry, I encountered an error during image search: {e}\")\n",
        "        elif \"open mentimeter\" in command:\n",
        "            respond(\"Opening Mentimeter.\")\n",
        "            webbrowser.open(\"https://www.mentimeter.com/\")\n",
        "        elif \"open kahoot\" in command:\n",
        "            respond(\"Opening Kahoot.\")\n",
        "            webbrowser.open(\"https://kahoot.com/\")\n",
        "        elif \"start class\" in command:\n",
        "            start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"INSERT INTO classes (start_time) VALUES (?)\", (start_time,))  # Only start time\n",
        "            conn.commit()\n",
        "            respond(\"Class started.\")\n",
        "        elif \"end class\" in command:\n",
        "            end_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"UPDATE classes SET end_time =? WHERE end_time IS NULL ORDER BY id DESC LIMIT 1\", (end_time,)) # Update the latest started class\n",
        "            conn.commit()\n",
        "            respond(\"Class ended.\")\n",
        "        elif \"google\" in command or \"chrome\" in command or \"browser\" in command:\n",
        "            respond(\"Opening Google.\")\n",
        "            webbrowser.open(\"www.google.com\")  # Or \"https://www.google.com\"\n",
        "        elif \"exit\" in command:\n",
        "            should_run = False\n",
        "        else:\n",
        "            respond(\"I don't understand that command.\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    while should_run:\n",
        "        command = listen_for_command()  # Directly listen for command\n",
        "        perform_command(command)\n",
        "        time.sleep(1)\n",
        "    respond(\"Goodbye.\")\n",
        "    conn.close() # Close database connection when exiting\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v_L3NEjHNkB"
      },
      "source": [
        "Trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "d81e410a596244fabfc28832b9227a10",
            "af4ed06eb18b4e6d9c2adf2bea9b1ad8",
            "b63c4f29a0d747d586608fbed80753c2",
            "ccdd759f2d8b407abac3761f3699a1d3"
          ]
        },
        "id": "ZpI85x4Cgt2Z",
        "outputId": "563dd711-d9d4-4bd0-ad98-01c39cc10f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing...\n",
            "\n",
            "--- Cache Directory Setup ---\n",
            "Ensured cache directory exists: c:\\Users\\edwar\\Downloads\\models\n",
            "Write permissions confirmed for: c:\\Users\\edwar\\Downloads\\models\n",
            "--- Cache Setup OK ---\n",
            "\n",
            "--- Model Loading ---\n",
            "Attempting to load model: EdwardFang09/whisper-base-TA-2025_v2-ct2\n",
            "Using cache directory: c:\\Users\\edwar\\Downloads\\models\n",
            "Device: cuda, Compute Type: default\n",
            "Calling WhisperModel constructor...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d81e410a596244fabfc28832b9227a10",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.bin:   0%|          | 0.00/145M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af4ed06eb18b4e6d9c2adf2bea9b1ad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/353 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b63c4f29a0d747d586608fbed80753c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccdd759f2d8b407abac3761f3699a1d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocabulary.json:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WhisperModel constructor finished.\n",
            "Model loaded successfully into 'base_model' variable.\n",
            "--- Model Loading OK ---\n",
            "\n",
            "--- Database Setup ---\n",
            "Connecting to database: class_data.db\n",
            "Database initialized.\n",
            "--- Database Setup OK ---\n",
            "\n",
            "========================================\n",
            "      VOICE ASSISTANT INITIALIZED      \n",
            "========================================\n",
            "Responding: Assistant sora activated and ready.\n",
            "\n",
            "Say 'sora' followed by a command.\n",
            "Examples:\n",
            "- 'sora search for cats'\n",
            "- 'sora open mentimeter'\n",
            "- 'sora open kahoot'\n",
            "- 'sora start class'\n",
            "- 'sora end class'\n",
            "- 'sora exit'\n",
            "- 'sora open google'\n",
            "----------------------------------------\n",
            "\n",
            "Listening...\n",
            "No speech detected within timeout.\n",
            "\n",
            "Listening...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 409\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# --- Entry Point ---\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[2], line 390\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# Main loop: Listen -> Transcribe -> Match -> Execute\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m should_run:\n\u001b[1;32m--> 390\u001b[0m     command_data \u001b[38;5;241m=\u001b[39m \u001b[43mlisten_for_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmicrophone\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pass the microphone object\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_run: \u001b[38;5;66;03m# Check if exit command was processed in perform_command\u001b[39;00m\n\u001b[0;32m    392\u001b[0m          perform_command(command_data)\n",
            "Cell \u001b[1;32mIn[2], line 176\u001b[0m, in \u001b[0;36mlisten_for_command\u001b[1;34m(microphone_source)\u001b[0m\n\u001b[0;32m    174\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(s, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# Listen with timeouts to prevent indefinite blocking\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphrase_time_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mWaitTimeoutError:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo speech detected within timeout.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[1;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[0;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\speech_recognition\\__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import warnings\n",
        "import time\n",
        "import webbrowser\n",
        "import pyttsx3\n",
        "import os\n",
        "from faster_whisper import WhisperModel\n",
        "import sqlite3\n",
        "import datetime\n",
        "from thefuzz import fuzz\n",
        "import numpy as np\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# --- Cache Directory ---\n",
        "# Use a simple, absolute path to avoid issues with relative paths.\n",
        "# Ensure this directory exists OR the script has permission to create it.\n",
        "# If you prefer the script's directory, change back to \"./models_cache\",\n",
        "# but absolute paths are often more reliable for caching.\n",
        "# On Linux/Jetson, this might be \"/home/user/hf_models_cache\" or \"/mnt/external/hf_cache\"\n",
        "CUSTOM_CACHE_DIR = \"./models\" # Example for Windows - CHANGE IF NEEDED\n",
        "\n",
        "# --- Model Configuration ---\n",
        "MODEL_PATH = \"EdwardFang09/whisper-base-TA-2025_v2-ct2\" # Use the standard OpenAI base model\n",
        "DEVICE = \"cuda\" # Ensure CUDA is correctly set up\n",
        "\n",
        "# --- Compute Type ---\n",
        "# Start with \"default\" or \"float32\" to ensure model downloads correctly first.\n",
        "# If successful, you can change back to \"float16\" for potential speed/memory benefits.\n",
        "# \"float16\" might require specific GPU capabilities or CUDA versions.\n",
        "COMPUTE_TYPE = \"default\"\n",
        "# COMPUTE_TYPE = \"float16\" # Change back later if \"default\" works\n",
        "\n",
        "ASSISTANT_NAME = \"sora\" # Trigger word (lowercase)\n",
        "DATABASE_FILE = \"class_data.db\"\n",
        "AUDIO_FILENAME = \"command_temp.wav\" # Temporary audio file\n",
        "\n",
        "# --- Command Recognition Settings ---\n",
        "CONFIDENCE_THRESHOLD_TYPE = \"dynamic\" # 'dynamic' or 'fixed'\n",
        "FIXED_CONFIDENCE_THRESHOLD = 75 # Used if CONFIDENCE_THRESHOLD_TYPE is 'fixed'\n",
        "# Minimum threshold if using dynamic, prevents overly low thresholds\n",
        "DYNAMIC_MIN_THRESHOLD = 60\n",
        "\n",
        "# Define commands: Keys are for internal use, Values are what fuzzy matching compares against\n",
        "COMMANDS = {\n",
        "    \"search\": \"search for\", # User says \"sora search for cats\"\n",
        "    \"open_menti\": \"open mentimeter\",\n",
        "    \"open_kahoot\": \"open kahoot\",\n",
        "    \"start_class\": \"start class\",\n",
        "    \"end_class\": \"end class\",\n",
        "    \"exit\": \"exit\",\n",
        "    \"google\": \"open google\", # Changed for clarity\n",
        "    # Add more commands here\n",
        "}\n",
        "\n",
        "# --- Initialization ---\n",
        "print(\"Initializing...\")\n",
        "recognizer = sr.Recognizer()\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# --- Setup Cache Directory ---\n",
        "print(f\"\\n--- Cache Directory Setup ---\")\n",
        "try:\n",
        "    # Ensure the chosen cache directory exists\n",
        "    os.makedirs(CUSTOM_CACHE_DIR, exist_ok=True)\n",
        "    abs_cache_path = os.path.abspath(CUSTOM_CACHE_DIR)\n",
        "    print(f\"Ensured cache directory exists: {abs_cache_path}\")\n",
        "\n",
        "    # Test write permission (optional but helpful)\n",
        "    test_file_path = os.path.join(CUSTOM_CACHE_DIR, 'permission_test.txt')\n",
        "    with open(test_file_path, 'w') as f:\n",
        "        f.write('test')\n",
        "    os.remove(test_file_path)\n",
        "    print(f\"Write permissions confirmed for: {abs_cache_path}\")\n",
        "except Exception as e:\n",
        "    abs_cache_path = os.path.abspath(CUSTOM_CACHE_DIR)\n",
        "    print(f\"\\n--- ERROR: Cache Directory Problem ---\")\n",
        "    print(f\"Could not create or write to cache directory '{abs_cache_path}': {e}\")\n",
        "    print(\"Please ensure the path is correct and you have write permissions.\")\n",
        "    print(\"Script will now exit.\")\n",
        "    exit() # Exit if cache directory setup fails\n",
        "print(f\"--- Cache Setup OK ---\")\n",
        "\n",
        "# --- Load Model (Only Once) ---\n",
        "print(f\"\\n--- Model Loading ---\")\n",
        "base_model = None # Initialize base_model to None\n",
        "try:\n",
        "    print(f\"Attempting to load model: {MODEL_PATH}\")\n",
        "    print(f\"Using cache directory: {abs_cache_path}\")\n",
        "    print(f\"Device: {DEVICE}, Compute Type: {COMPUTE_TYPE}\")\n",
        "    print(\"Calling WhisperModel constructor...\") # Log before call\n",
        "\n",
        "    # *** This is the ONLY place the model is loaded ***\n",
        "    base_model = WhisperModel(\n",
        "        MODEL_PATH,\n",
        "        device=DEVICE,\n",
        "        compute_type=COMPUTE_TYPE,\n",
        "        download_root=CUSTOM_CACHE_DIR, # Use the verified cache path\n",
        "        local_files_only=False # IMPORTANT: Allow downloading\n",
        "    )\n",
        "\n",
        "    print(\"WhisperModel constructor finished.\") # Log after call\n",
        "\n",
        "    # Verify model object was created\n",
        "    if base_model:\n",
        "         print(\"Model loaded successfully into 'base_model' variable.\")\n",
        "         print(f\"--- Model Loading OK ---\")\n",
        "    else:\n",
        "         # This case shouldn't happen if WhisperModel succeeded without error, but check anyway\n",
        "         print(\"WARNING: WhisperModel call finished but 'base_model' is still None.\")\n",
        "         raise RuntimeError(\"Model object not created after WhisperModel call.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- FATAL ERROR: Model Loading Failed ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    print(\"\\nTroubleshooting suggestions:\")\n",
        "    print(f\"1. Manually delete the cache directory and try again: {abs_cache_path}\")\n",
        "    print(f\"2. Ensure you have a stable internet connection (for first download).\")\n",
        "    print(f\"3. Verify model ID '{MODEL_PATH}' exists on Hugging Face Hub.\")\n",
        "    print(f\"4. Check you have enough disk space in: {abs_cache_path}\")\n",
        "    print(f\"5. Ensure selected device ('{DEVICE}') is available and drivers are installed.\")\n",
        "    print(f\"6. Check compute type ('{COMPUTE_TYPE}') compatibility. Try 'default' or 'float32' if issues persist.\")\n",
        "    print(f\"7. Check if Anti-Virus/Firewall software is interfering with downloads or file access.\")\n",
        "    print(f\"8. Ensure the cache path '{abs_cache_path}' is simple and accessible.\")\n",
        "    print(\"\\nScript will now exit.\")\n",
        "    # *** IMPORTANT: Ensure script exits if model loading fails ***\n",
        "    exit()\n",
        "\n",
        "# --- Database Setup ---\n",
        "print(f\"\\n--- Database Setup ---\")\n",
        "try:\n",
        "    print(f\"Connecting to database: {DATABASE_FILE}\")\n",
        "    conn = sqlite3.connect(DATABASE_FILE)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS classes (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            start_time TEXT,\n",
        "            end_time TEXT\n",
        "        )\n",
        "    ''')\n",
        "    conn.commit()\n",
        "    print(\"Database initialized.\")\n",
        "    print(f\"--- Database Setup OK ---\")\n",
        "except Exception as e:\n",
        "    print(f\"--- FATAL ERROR: Database Setup Failed ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    print(\"\\nScript will now exit.\")\n",
        "    exit()\n",
        "\n",
        "# --- Core Functions ---\n",
        "def respond(text):\n",
        "    \"\"\"Sends text to the TTS engine.\"\"\"\n",
        "    print(f\"Responding: {text}\")\n",
        "    try:\n",
        "        engine.say(text)\n",
        "        engine.runAndWait()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during TTS processing: {e}\")\n",
        "\n",
        "def listen_for_command(microphone_source):\n",
        "    \"\"\"Listens for audio, transcribes, checks trigger word, and matches command.\"\"\"\n",
        "    # Ensure base_model is loaded before proceeding\n",
        "    if not base_model:\n",
        "         print(\"ERROR: Model was not loaded. Cannot transcribe.\")\n",
        "         return None\n",
        "\n",
        "    with microphone_source as s:\n",
        "        print(\"\\nListening...\")\n",
        "        try:\n",
        "            recognizer.adjust_for_ambient_noise(s, duration=0.5)\n",
        "            # Listen with timeouts to prevent indefinite blocking\n",
        "            audio = recognizer.listen(s, timeout=7, phrase_time_limit=15)\n",
        "        except sr.WaitTimeoutError:\n",
        "            print(\"No speech detected within timeout.\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error during listening phase: {e}\")\n",
        "            return None\n",
        "\n",
        "    try:\n",
        "        # Save audio temporarily for faster-whisper\n",
        "        with open(AUDIO_FILENAME, \"wb\") as f:\n",
        "            f.write(audio.get_wav_data())\n",
        "\n",
        "        # Transcribe using faster-whisper\n",
        "        # Consider adding VAD filter if background noise is an issue: vad_filter=True\n",
        "        segments, info = base_model.transcribe(AUDIO_FILENAME, language='en', beam_size=5)\n",
        "        print(f\"Detected language '{info.language}' with probability {info.language_probability:.2f}\")\n",
        "\n",
        "        full_command_text = \"\".join(segment.text for segment in segments).strip().lower()\n",
        "        print(f\"Transcribed Text: '{full_command_text}'\")\n",
        "\n",
        "        # --- Trigger Word Check ---\n",
        "        if not full_command_text or not full_command_text.startswith(ASSISTANT_NAME):\n",
        "             print(f\"No command or trigger word '{ASSISTANT_NAME}' not detected at start.\")\n",
        "             return None\n",
        "\n",
        "        # Extract command phrase after trigger word\n",
        "        command_phrase = full_command_text.replace(ASSISTANT_NAME, \"\", 1).strip()\n",
        "        if not command_phrase:\n",
        "            print(\"Trigger word heard, but no command followed.\")\n",
        "            # Maybe respond(\"Yes?\") or similar? For now, just ignore.\n",
        "            return None\n",
        "        print(f\"Command Phrase (after trigger): '{command_phrase}'\")\n",
        "\n",
        "        # --- Fuzzy Matching Logic ---\n",
        "        best_match_key = None\n",
        "        best_score = 0\n",
        "        scores = []\n",
        "\n",
        "        print(\"Comparing against commands:\")\n",
        "        for cmd_key, target_phrase in COMMANDS.items():\n",
        "            # Use partial_ratio for commands expecting follow-up words (like 'search for')\n",
        "            # Use regular ratio for commands needing exact matches\n",
        "            if cmd_key == \"search\":\n",
        "                 score = fuzz.partial_ratio(command_phrase, target_phrase)\n",
        "            else:\n",
        "                 score = fuzz.ratio(command_phrase, target_phrase)\n",
        "\n",
        "            print(f\"- vs '{target_phrase}': Score {score}\")\n",
        "            scores.append(score)\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match_key = cmd_key\n",
        "\n",
        "        # --- Confidence Check ---\n",
        "        if CONFIDENCE_THRESHOLD_TYPE == \"dynamic\":\n",
        "            if not scores: # Avoid numpy errors if COMMANDS is empty\n",
        "                 confidence_threshold = DYNAMIC_MIN_THRESHOLD\n",
        "            else:\n",
        "                 scores_array = np.array(scores)\n",
        "                 average_score = np.mean(scores_array)\n",
        "                 standard_deviation = np.std(scores_array)\n",
        "                 # Calculate dynamic threshold but ensure it's not below the minimum\n",
        "                 confidence_threshold = max(average_score + standard_deviation, DYNAMIC_MIN_THRESHOLD)\n",
        "            print(f\"Dynamic Threshold Calculated: {confidence_threshold:.2f}\")\n",
        "        else: # fixed threshold\n",
        "            confidence_threshold = FIXED_CONFIDENCE_THRESHOLD\n",
        "            print(f\"Using Fixed Threshold: {confidence_threshold}\")\n",
        "\n",
        "        # Check if the best match meets the threshold\n",
        "        if best_match_key and best_score >= confidence_threshold:\n",
        "            print(f\"Confident Match: Key='{best_match_key}', Score={best_score}, Threshold={confidence_threshold:.2f}\")\n",
        "            # Return the matched key AND the specific phrase spoken after the trigger word\n",
        "            return (best_match_key, command_phrase)\n",
        "        else:\n",
        "            print(f\"Command not recognized with sufficient confidence (Best Score: {best_score} < Threshold: {confidence_threshold:.2f}).\")\n",
        "            # Optional: Respond that the command wasn't understood\n",
        "            # respond(\"Sorry, I didn't quite catch that command.\")\n",
        "            return None\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Could not understand audio clearly after listening.\")\n",
        "        return None\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Speech recognition service error (if using online recognizer): {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during transcription or command matching: {e}\")\n",
        "        # Log the traceback for debugging if needed:\n",
        "        # import traceback\n",
        "        # traceback.print_exc()\n",
        "        return None\n",
        "    finally:\n",
        "        # Clean up temporary audio file\n",
        "        if os.path.exists(AUDIO_FILENAME):\n",
        "             try:\n",
        "                 os.remove(AUDIO_FILENAME)\n",
        "             except OSError as e:\n",
        "                 print(f\"Warning: Could not delete temp audio file {AUDIO_FILENAME}: {e}\")\n",
        "\n",
        "\n",
        "def perform_command(command_data):\n",
        "    \"\"\"Executes the action based on the matched command key and original phrase.\"\"\"\n",
        "    global should_run # Need global scope to modify should_run for exit command\n",
        "    if not command_data:\n",
        "        return # No valid command was recognized\n",
        "\n",
        "    command_key, original_phrase = command_data # Unpack the tuple\n",
        "    print(f\"\\n--- Executing Command ---\")\n",
        "    print(f\"Key: '{command_key}', Original Phrase: '{original_phrase}'\")\n",
        "\n",
        "    # Use if/elif based on the command_key returned by fuzzy matching\n",
        "    if command_key == \"search\":\n",
        "        # Extract the query part after \"search for\"\n",
        "        # Assumes the target phrase in COMMANDS is \"search for\"\n",
        "        query = original_phrase.replace(COMMANDS[command_key], \"\").strip()\n",
        "        if query:\n",
        "            respond(f\"Searching Google Images for {query}\")\n",
        "            try:\n",
        "                search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
        "                webbrowser.open(search_url)\n",
        "            except Exception as e:\n",
        "                respond(f\"Sorry, I encountered an error opening the browser for image search: {e}\")\n",
        "        else:\n",
        "            respond(\"What would you like me to search for? Please say 'search for' followed by your query.\")\n",
        "\n",
        "    elif command_key == \"open_menti\":\n",
        "        respond(\"Opening Mentimeter.\")\n",
        "        try:\n",
        "            webbrowser.open(\"https://www.mentimeter.com/\")\n",
        "        except Exception as e:\n",
        "             respond(f\"Sorry, I encountered an error opening Mentimeter: {e}\")\n",
        "\n",
        "    elif command_key == \"open_kahoot\":\n",
        "        respond(\"Opening Kahoot.\")\n",
        "        try:\n",
        "            webbrowser.open(\"https://kahoot.com/\")\n",
        "        except Exception as e:\n",
        "             respond(f\"Sorry, I encountered an error opening Kahoot: {e}\")\n",
        "\n",
        "    elif command_key == \"start_class\":\n",
        "        try:\n",
        "            start_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            cursor.execute(\"INSERT INTO classes (start_time) VALUES (?)\", (start_time,))\n",
        "            conn.commit()\n",
        "            respond(\"Class started and time logged.\")\n",
        "        except Exception as e:\n",
        "            respond(f\"Sorry, failed to log class start time: {e}\")\n",
        "\n",
        "    elif command_key == \"end_class\":\n",
        "        try:\n",
        "            # Find the ID of the latest class entry that hasn't ended yet\n",
        "            cursor.execute(\"SELECT id FROM classes WHERE end_time IS NULL ORDER BY id DESC LIMIT 1\")\n",
        "            last_class = cursor.fetchone()\n",
        "            if last_class:\n",
        "                end_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                cursor.execute(\"UPDATE classes SET end_time = ? WHERE id = ?\", (end_time, last_class[0]))\n",
        "                conn.commit()\n",
        "                respond(\"Class ended and time logged.\")\n",
        "            else:\n",
        "                respond(\"No active class found in the log to end.\")\n",
        "        except Exception as e:\n",
        "            respond(f\"Sorry, failed to log class end time: {e}\")\n",
        "\n",
        "    elif command_key == \"google\":\n",
        "        respond(\"Opening Google.\")\n",
        "        try:\n",
        "            webbrowser.open(\"https://www.google.com\")\n",
        "        except Exception as e:\n",
        "             respond(f\"Sorry, I encountered an error opening Google: {e}\")\n",
        "\n",
        "    elif command_key == \"exit\":\n",
        "        respond(\"Exiting program now.\")\n",
        "        should_run = False # Set flag to stop the main loop\n",
        "\n",
        "    else:\n",
        "        # This case should ideally not be reached if COMMANDS dict is correct\n",
        "        respond(f\"I understood the command key '{command_key}' but don't have an action defined for it.\")\n",
        "\n",
        "    print(f\"--- Command Execution Finished ---\")\n",
        "\n",
        "\n",
        "# --- Main Application Loop ---\n",
        "def main():\n",
        "    global should_run # Allow modifying the global flag\n",
        "    should_run = True # Ensure the loop runs at least once\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(\"      VOICE ASSISTANT INITIALIZED      \")\n",
        "    print(\"=\" * 40)\n",
        "    respond(f\"Assistant {ASSISTANT_NAME} activated and ready.\")\n",
        "    print(f\"\\nSay '{ASSISTANT_NAME}' followed by a command.\")\n",
        "    print(f\"Examples:\")\n",
        "    for key, phrase in COMMANDS.items():\n",
        "        if key == \"search\":\n",
        "             print(f\"- '{ASSISTANT_NAME} {phrase} cats'\")\n",
        "        else:\n",
        "             print(f\"- '{ASSISTANT_NAME} {phrase}'\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Initialize microphone object once\n",
        "    try:\n",
        "         microphone = sr.Microphone()\n",
        "    except Exception as e:\n",
        "         print(f\"\\n--- FATAL ERROR: Microphone Setup Failed ---\")\n",
        "         print(f\"Could not initialize microphone: {e}\")\n",
        "         print(\"Please ensure a microphone is connected and recognized by the system.\")\n",
        "         print(\"Check microphone permissions if necessary.\")\n",
        "         print(\"Script will now exit.\")\n",
        "         exit()\n",
        "\n",
        "    # Main loop: Listen -> Transcribe -> Match -> Execute\n",
        "    while should_run:\n",
        "        command_data = listen_for_command(microphone) # Pass the microphone object\n",
        "        if should_run: # Check if exit command was processed in perform_command\n",
        "             perform_command(command_data)\n",
        "        # Brief pause can sometimes help, but listening timeout mostly handles waiting\n",
        "        # time.sleep(0.1)\n",
        "\n",
        "    # --- Cleanup ---\n",
        "    print(\"\\n--- Shutting Down ---\")\n",
        "    respond(\"Goodbye.\")\n",
        "    if conn:\n",
        "        try:\n",
        "             conn.close()\n",
        "             print(\"Database connection closed.\")\n",
        "        except Exception as e:\n",
        "             print(f\"Error closing database connection: {e}\")\n",
        "    print(\"Program finished.\")\n",
        "\n",
        "# --- Entry Point ---\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8ChUytFgt2a"
      },
      "outputs": [],
      "source": [
        "pip install -U ctranslate2 transformers huggingface_hub"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}